# Awesome-LLM-Hallucination
Collection of LLM hallucination Papers

## Contents
- Conference Papers
	- 2024: ACL, EMNLP, NAACL, Others
	- 2023: ACL, EMNLP, NAACL, Others
	- 2022: ACL, EMNLP, NAACL, Others
	- 2021: ACL, EMNLP, NAACL, Others

## Conference Papers
### 2024 ACL
Coming ...
### 2024 EMNLP
Coming ...
### 2024 NAACL
- Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision [[pdf]](https://aclanthology.org/2024.naacl-long.23/)
- On Large Language Modelsâ€™ Hallucination with Regard to Known Facts [[pdf]](https://aclanthology.org/2024.naacl-long.60/)
- Language Models Hallucinate, but May Excel at Fact Verification [[pdf]](https://aclanthology.org/2024.naacl-long.62/)
- **[Can Knowledge Graphs Reduce Hallucinations in  LLMs? : A Survey](https://aclanthology.org/2024.naacl-long.219/)**
- **[TofuEval: Evaluating Hallucinations of  LLMs on Topic-Focused Dialogue Summarization](https://aclanthology.org/2024.naacl-long.251/)**
- [Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?](https://aclanthology.org/2024.naacl-long.424/)
- **[Hallucination Diversity-Aware Active Learning for Text Summarization](https://aclanthology.org/2024.naacl-long.479/)**
- **[ALOHa: A New Measure for Hallucination in Captioning Models](https://aclanthology.org/2024.naacl-short.30/)**
-   
Trusting Your Evidence: Hallucinate Less with Context-aware Decoding


<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyNjg5Mjc0Miw3Mjk2NzQ4NDAsLTg4Nz
IxNTI0MCwyMDk0Mjg3MDE2LC05NTM1NzY1MDIsLTY2NjQwMzcz
Myw5Mjc3OTcxMTgsMjEyMDA0MjE1MCwtNTExNzc4NjQ5LDIwND
k5MjE0OTMsLTQ4MDc4OTk3MiwtMTExODU5NzI5Nl19
-->